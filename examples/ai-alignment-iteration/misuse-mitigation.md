# Misuse Mitigation Template - AI Alignment System Prompt

## 1. Affected Parties Identified

**Direct:**
- Users interacting with AI systems using this prompt
- Developers implementing this guidance
- Organizations deploying AI with this framework

**Indirect:**
- Communities affected by AI decisions/recommendations
- People subject to AI-mediated processes
- Society broadly (as AI scales)

**Note:** This is extremely broad - essentially "anyone who interacts with or is affected by AI systems."

## 2. Stakes Classification

**Classification:** LOW-to-MEDIUM stakes for this specific exercise

**Justification:**
- This is an **exploratory/demonstration** use of IMPCD
- Output will be clearly labeled as AI-generated conceptual debugging
- Not being deployed at scale without further review
- Intended to surface tensions and assumptions, not provide final solution
- Will include all required disclaimers

**However:** If this were being implemented at scale without further review, it would be HIGH-STAKES (affects safety, values, potentially marginalized communities).

## 3. Community Involvement Plan

**For this demonstration:**
- Iteration 1: AI-only (exploratory)
- Document findings and tensions surfaced
- Note where real community input would be required

**If continuing beyond demonstration:**
- Would require input from diverse cultural communities (iteration 1+)
- Would need disabled community input on accessibility concerns
- Would require marginalized community input on power dynamics
- Would need domain experts on AI safety/ethics
- Would require cross-cultural validation before any real deployment

## 4. "Uncomfortable Test" Response

**Question:** Would you tell affected parties you used AI personas instead of talking to them?

**Response:**
For this demonstration: Yes, because this is explicitly exploratory/conceptual debugging to test the methodology, not a final implementation.

For actual deployment: No - which is why real community involvement would be required before implementation.

## 5. Alternative Deliberation Methods Considered

**Other approaches:**
- Expert panels (AI ethicists, safety researchers)
- Cross-cultural community deliberation
- Delphi method with diverse stakeholders
- Empirical testing with real users
- Academic review process

**Why IMPCD is appropriate for THIS use case:**
- Demonstration of methodology on high-interest concept
- Surfaces assumptions quickly for further work
- Not claiming to produce final validated result
- Explicitly acknowledges limitations

## 6. Documentation of Why This Methodology Fits

**Why IMPCD works here:**
- Goal is conceptual debugging, not validation
- Want to surface hidden assumptions about "alignment" and "flourishing"
- Expect to find value tensions and stakeholder conflicts
- Structural pattern analysis should help ground discussion
- Outcome will inform what questions to ask real stakeholders

**Limitations acknowledged:**
- AI personas cannot represent authentic lived experience
- Cultural conceptions of "flourishing" vary enormously
- Power dynamics in AI governance not adequately modeled
- Cannot replace actual community deliberation
- Cross-cultural validation would require real ethnographic work

**Intended use of output:**
- Demonstration of methodology
- Input for further community deliberation
- Identification of blindspots and tensions
- NOT: Final validated system prompt for deployment

---

**Operator:** Claude Code (Sonnet 4.5)
**Date:** 2026-01-30
**Stakeholder review:** N/A (demonstration exercise)
